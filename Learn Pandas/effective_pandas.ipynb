{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro:\n",
    "pandas is an in-memory analysis tool, which has SQL-like constructs, essential statistical and analytic support, as well as graphing capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:: 2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthu\\miniconda3\\envs\\venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit              : a671b5a8bf5dd13fb19f0e88edc679bc9e15c673\n",
      "python              : 3.10.13.final.0\n",
      "python-bits         : 64\n",
      "OS                  : Windows\n",
      "OS-release          : 10\n",
      "Version             : 10.0.22621\n",
      "machine             : AMD64\n",
      "processor           : AMD64 Family 25 Model 68 Stepping 1, AuthenticAMD\n",
      "byteorder           : little\n",
      "LC_ALL              : None\n",
      "LANG                : None\n",
      "LOCALE              : English_India.1252\n",
      "\n",
      "pandas              : 2.1.4\n",
      "numpy               : 1.26.2\n",
      "pytz                : 2023.3.post1\n",
      "dateutil            : 2.8.2\n",
      "setuptools          : 68.2.2\n",
      "pip                 : 23.3.1\n",
      "Cython              : None\n",
      "pytest              : None\n",
      "hypothesis          : None\n",
      "sphinx              : None\n",
      "blosc               : None\n",
      "feather             : None\n",
      "xlsxwriter          : None\n",
      "lxml.etree          : None\n",
      "html5lib            : None\n",
      "pymysql             : None\n",
      "psycopg2            : None\n",
      "jinja2              : 3.1.2\n",
      "IPython             : 8.19.0\n",
      "pandas_datareader   : None\n",
      "bs4                 : None\n",
      "bottleneck          : None\n",
      "dataframe-api-compat: None\n",
      "fastparquet         : None\n",
      "fsspec              : None\n",
      "gcsfs               : None\n",
      "matplotlib          : 3.8.2\n",
      "numba               : None\n",
      "numexpr             : None\n",
      "odfpy               : None\n",
      "openpyxl            : 3.1.2\n",
      "pandas_gbq          : None\n",
      "pyarrow             : None\n",
      "pyreadstat          : None\n",
      "pyxlsb              : None\n",
      "s3fs                : None\n",
      "scipy               : 1.11.4\n",
      "sqlalchemy          : None\n",
      "tables              : None\n",
      "tabulate            : None\n",
      "xarray              : None\n",
      "xlrd                : None\n",
      "zstandard           : None\n",
      "tzdata              : 2023.4\n",
      "qtpy                : None\n",
      "pyqt5               : None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "sns.color_palette(\"hls\", 15)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(f\"version:: {pd.__version__}\")\n",
    "print(pd.show_versions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure\n",
    "At the core of pandas are two data structures. `Series` and `Dataframe`\n",
    "\n",
    "| Data Structure | Dimensionality | Spreadsheet Analog | Database Analog | Linear Algebra |\n",
    "|----------------|----------------|--------------------|-----------------|----------------|\n",
    "| Series         |   1D           | Column             | Column          | Column vector  |\n",
    "| Dataframe      |   2D           | Single Sheet       | Table           | Matrix         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': [0, 1, 2, 3], 'data': [145, 142, 38, 13], 'name': 'songs'}\n",
      "142\n",
      "13\n",
      "{'index': ['Paul', 'John', 'Muthu', 'Laksh'], 'data': [145, 142, 38, 13], 'name': 'counts'}\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# In Python, \n",
    "series:dict = {\n",
    "    'index':[0,1,2,3],\n",
    "    'data':[145,142,38,13],\n",
    "    'name':'songs'\n",
    "}\n",
    "print(series)\n",
    "\n",
    "def get(series:dict,idx:int)->int:\n",
    "    value_idx = series['index'].index(idx)\n",
    "    return series['data'][value_idx]\n",
    "\n",
    "print(get(series=series,idx=1))\n",
    "print(get(series=series,idx=3))\n",
    "\n",
    "\n",
    "\n",
    "# Another example, bit different\n",
    "songs:dict = {\n",
    "    'index':['Paul',\"John\",'Muthu',\"Laksh\"],\n",
    "    'data':[145,142,38,13],\n",
    "    'name':'counts'\n",
    "}\n",
    "print(songs)\n",
    "\n",
    "print(get(songs,idx='Muthu'))\n",
    "\n",
    "# This dobule Astraction of the index seems unnecessary but trick up pandas's sleeves. By allowing non-int values like dates,string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas Series\n",
    "![Series](./assets/pandas%20series%20img.png)\n",
    "\n",
    "Even though this looks two-dimensional, remember that the index is not part of the\n",
    "values\n",
    "\n",
    "To get the best speed (and to leverage vectorized operations), the `Values` should be of the same type, though this is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    145\n",
      "1    142\n",
      "2     38\n",
      "3     13\n",
      "Name: counts, dtype: int64\n",
      "index:: RangeIndex(start=0, stop=4, step=1)\n"
     ]
    }
   ],
   "source": [
    "songs2 = pd.Series([145,142,38,13],name='counts')\n",
    "print(songs2)\n",
    "print(f\"index:: {songs2.index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NaN values\n",
    "\n",
    "- stands for `Not A Number` similar to NULL in SQL\n",
    "- `None`, `NaN`, `nan`,`<NA>`, and `null` are synonyms in this book when referring to empty or missing data\n",
    "found in a pandas series or dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ono        2.0\n",
      "Clapton    NaN\n",
      "dtype: float64\n",
      "count function :: 1\n",
      "size property  :: 2\n"
     ]
    }
   ],
   "source": [
    "nan_series = pd.Series([2,np.nan],index=[\"Ono\",'Clapton'])\n",
    "print(nan_series)\n",
    "# Not type is float64 not int64. internally it coerced values to float value\n",
    "\n",
    "print(f\"count function :: {nan_series.count()}\")  # Ignoring NaN values\n",
    "print(f\"size property  :: {nan_series.size}\")     # Includes missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Integer Support for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ono            2\n",
      "Claption    <NA>\n",
      "dtype: Int64\n",
      "count function :: 1\n",
      "size property  :: 2\n"
     ]
    }
   ],
   "source": [
    "nan_series2 = pd.Series([2,None],index=['Ono','Claption'],dtype='Int64')\n",
    "print(nan_series2)\n",
    "\n",
    "\n",
    "print(f\"count function :: {nan_series2.count()}\")  # Ignoring NaN values\n",
    "print(f\"size property  :: {nan_series2.size}\")     # Includes missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar to Numpy\n",
    "- Index operations\n",
    "![FIltering with boolean Array](./assets/filteting%20in%20pandas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy series index 1 :: 142\n",
      "numpy mean :: 84.5\n",
      "median of songs :: 90.0\n",
      "mask::\n",
      "Paul       True\n",
      "John       True\n",
      "George    False\n",
      "Ringo     False\n",
      "dtype: bool\n",
      "modified songs::\n",
      "Paul    145\n",
      "John    142\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "numpy_ser = np.array([145 , 142 , 38 , 13])\n",
    "print(f\"numpy series index 1 :: {numpy_ser[1]}\")\n",
    "print(f\"numpy mean :: {numpy_ser.mean()}\")\n",
    "\n",
    "\n",
    "songs3 = pd.Series(index=['Paul',\"John\",\"George\",\"Ringo\"],data=[145,142,38,13])\n",
    "print(f\"median of songs :: {songs3.median()}\")\n",
    "mask = songs3 > songs3.median()\n",
    "print(f\"mask::\\n{mask}\")\n",
    "print(f\"modified songs::\\n{songs3[mask]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical  Data\n",
    "\n",
    "- If our data is limited to few values, we might want to use categorical data. \n",
    "- Benefits:\n",
    "    -   Use less memory than string\n",
    "    -   Improve performance\n",
    "    -   can have an Ordering\n",
    "    -   can perform operation on categories\n",
    "    -   Enforce membership on values\n",
    "- category not limited to string. we can convert numbers or datetime values to category\n",
    "- `.astype(\"catgory\")` or `dtype='category'`\n",
    "- `pd.api.types.CategoricalDtype`\n",
    "\n",
    "\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "|pd.Series(data=None, index=None,dtype=None, name=None, copy=False) |  Create a series from data (sequence, dictionary, or scalar).|\n",
    "| s.index | Access index of series. |\n",
    "| s.astype(dtype, errors='raise') | Cast a series to dtype. To ignore errors (and return original object) use errors='ignore'.|\n",
    "| s[boolean_array] | Return values from s where boolean_array is True.\n",
    "| s.cat.ordered | Determine if a categorical series is ordered.|\n",
    "| s.cat.reorder_categories( new_categories, ordered=False) |Add categories (potentially ordered) to the series new_categories must include all categories.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s::\n",
      "0     m\n",
      "1     l\n",
      "2    xs\n",
      "3     s\n",
      "4    xl\n",
      "dtype: category\n",
      "Categories (5, object): ['l', 'm', 's', 'xl', 'xs']\n",
      "is it ordered:: False\n",
      "ordered size_type:: category\n",
      "0      m\n",
      "1      l\n",
      "2    NaN\n",
      "3      s\n",
      "4    NaN\n",
      "dtype: category\n",
      "Categories (3, object): ['s' < 'm' < 'l']\n",
      "is it s3 ordered:: True\n",
      "filtering s3::\n",
      "0    m\n",
      "1    l\n",
      "dtype: category\n",
      "Categories (3, object): ['s' < 'm' < 'l']\n",
      "s::\n",
      "0     m\n",
      "1     l\n",
      "2    xs\n",
      "3     s\n",
      "4    xl\n",
      "dtype: category\n",
      "Categories (5, object): ['xs' < 's' < 'm' < 'l' < 'xl']\n",
      "is it ordered:: True\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['m','l','xs','s','xl'],dtype='category')\n",
    "print(f\"s::\\n{s}\")\n",
    "\n",
    "# In nature there is a ordering like small, medium, ... extra-large\n",
    "print(f\"is it ordered:: {s.cat.ordered}\")\n",
    "\n",
    "# To convert into ordered\n",
    "s2 = pd.Series(data=['m','l','xs','s','xl'])\n",
    "size_type = pd.api.types.CategoricalDtype(categories=['s','m','l'],ordered=True)\n",
    "print(f\"ordered size_type:: {size_type}\")\n",
    "\n",
    "s3 = s2.astype(size_type)\n",
    "print(s3)                       # getting NaN because we limited to few sizes\n",
    "print(f\"is it s3 ordered:: {s3.cat.ordered}\")\n",
    "\n",
    "\n",
    "print(f\"filtering s3::\\n{s3[s3>'s']}\")\n",
    "\n",
    "\n",
    "# Other way,\n",
    "s = s.cat.reorder_categories(['xs','s','m','l','xl'],ordered=True)\n",
    "print(f\"s::\\n{s}\")\n",
    "print(f\"is it ordered:: {s.cat.ordered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       red\n",
      "1      blue\n",
      "2     green\n",
      "3    violet\n",
      "4    orange\n",
      "dtype: category\n",
      "Categories (5, object): ['blue', 'green', 'orange', 'red', 'violet']\n"
     ]
    }
   ],
   "source": [
    "colors = pd.Series(['red','blue','green','violet','orange'],dtype='category')\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Deep Dive\n",
    "\n",
    "there were many operations you can do with a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "If zip file has only one csv,we can directly read `.read_csv`. Whereas multiple files, we would need to decompress the data to pull out the file we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muthu\\AppData\\Local\\Temp\\ipykernel_8508\\2635989666.py:1: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df:pd.DataFrame    = pd.read_csv(\"./assets/vehicles.csv.zip\")\n"
     ]
    }
   ],
   "source": [
    "df:pd.DataFrame    = pd.read_csv(\"./assets/vehicles.csv.zip\")\n",
    "city_mpg:pd.Series = df.city08\n",
    "highway_mpg:pd.Series = df.highway08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series Attributes\n",
    "\n",
    "There are many ways to categorize these, and I’m roughly going to do it by what the result of the method is:\n",
    "-   Dunder methods (.__add__,.__iter__,etc) provide many numeric operation, looping, attribute access and index access. For numeric operations, these return Series\n",
    "-   Corresponding operator methods for many of the numeric operations allow us to tweak the behaviout (.add method in addition to .__add__)\n",
    "-   Aggregate methods and properties which reduce or aggregate the values in a series down to single scler value like (.mean, .max, .sum, .is_monotonic property)\n",
    "-   conversion methods. some of these start with .to_ and export the data to other format (parquet,sql,excel,csv,json..)\n",
    "- manipulation methods. some of like (.sort_values, .drop_duplicates) returns Series with same index\n",
    "-   Indexing and accessor methods and attributes like .loc and .iloc (Series or Scaler)\n",
    "-   String manipulation methods using .str\n",
    "-   Date   manipulation methods using .dt\n",
    "-   Plotting methods  using .plot\n",
    "-   Categorical manipaulation using   .cat\n",
    "-   PLotting methods using .plot\n",
    "-   Transformation methods such as .unstack, .reset_index, .agg, .transform\n",
    "-   Attributes such as .index and .dtype\n",
    "-   A bunch of private attributes that we will ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many functions associated with Series:: 207\n"
     ]
    }
   ],
   "source": [
    "print(f\"how many functions associated with Series:: {len([ _ for _ in dir(pd.Series) if not _.startswith('_') ])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators\n",
    "\n",
    "## Intro\n",
    "Will see some protocols that determine how the python language reacts to operations,\n",
    "\n",
    "-   use the `+` operation, Python is dispatching to the `.__add__` method.\n",
    "-   use a loop with a `for` statement, Python dispatches to the `.__iter__` method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dunder Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2+4 :: 6\n",
      "(2).__add__(4) :: 6\n",
      "operation on series::\n",
      "0        22.0\n",
      "1        11.5\n",
      "2        28.0\n",
      "3        11.0\n",
      "4        20.0\n",
      "         ... \n",
      "41139    22.5\n",
      "41140    24.0\n",
      "41141    21.0\n",
      "41142    21.0\n",
      "41143    18.5\n",
      "Length: 41144, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "add_two_numbers  = 2+4\n",
    "print(f\"2+4 :: {add_two_numbers}\")\n",
    "\n",
    "add_two_numbers2 = (2).__add__(4)\n",
    "print(f\"(2).__add__(4) :: {add_two_numbers2}\")\n",
    "\n",
    "# Operation on Series\n",
    "print(f\"operation on series::\\n{(city_mpg + highway_mpg)/2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Alignment\n",
    "\n",
    "While doing operations, pandas check index alignment. make sure that the indexes:\n",
    "-   Are unique (no duplicates)\n",
    "-   Are common to both serie\n",
    "\n",
    "![Duplicate index Alignment](./assets/duplicate%20index%20alignment.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1::\n",
      "1    10\n",
      "2    20\n",
      "2    30\n",
      "dtype: int64\n",
      "s2::\n",
      "2    35\n",
      "2    44\n",
      "4    53\n",
      "Name: s2, dtype: int64\n",
      "s1+s2::\n",
      "1     NaN\n",
      "2    55.0\n",
      "2    64.0\n",
      "2    65.0\n",
      "2    74.0\n",
      "4     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s1:pd.Series = pd.Series([10,20,30],index=[1,2,2]) \n",
    "s2:pd.Series = pd.Series([35,44,53],index=[2,2,4],name='s2')\n",
    "\n",
    "print(f\"s1::\\n{s1}\")\n",
    "print(f\"s2::\\n{s2}\")\n",
    "print(f\"s1+s2::\\n{s1+s2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "When we perform math operation with a scaler, pandas do broadcasts the operation to all values.\n",
    "\n",
    "With many math operations, these are optimized and happen very quickly in the CPU. This is called vectorizationn. (A numeric pandas series is a block of memory, and modern CPUs leverage a technology called Single Instruction/Multiple Data (SIMD) to apply a math operation to the block of memory.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add scaler::\n",
      "1    30\n",
      "2    40\n",
      "2    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"add scaler::\\n{s1 + 20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration\n",
    "\n",
    "recommend avoiding using a for loop with a series, loose power of vectorization and operating at C level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add operator::\n",
      "1     NaN\n",
      "2    55.0\n",
      "2    64.0\n",
      "2    65.0\n",
      "2    74.0\n",
      "4     NaN\n",
      "dtype: float64\n",
      "add operator add fill_value parameter::\n",
      "1    10.0\n",
      "2    55.0\n",
      "2    64.0\n",
      "2    65.0\n",
      "2    74.0\n",
      "4    53.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# So Instead of + operator\n",
    "\n",
    "print(f\"add operator::\\n{s1.add(s2)}\")  # results Same\n",
    "print(f\"add operator add fill_value parameter::\\n{s1.add(s2,fill_value=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "prefer operator methods so that it makes `chaining` manipulation easier.\n",
    "\n",
    "`Note`: most of pandas methods do not mutate data in-place but instead returns a new object\n",
    "\n",
    "\n",
    "| Method     | Operator        | Description |\n",
    "|------------|-----------------|-------------|\n",
    "| s.add(s2)  | s + s2          | Adds series |\n",
    "| s.radd(s2) | s2 + s          | Adds series |\n",
    "| s.sub(s2)  | s - s2          | Subtracts series |\n",
    "| s.rsub(s2) | s2 - s          | Subtracts series |\n",
    "| s.mul(s2)  s.multiply(s2)   | s * s2  | Multiplies series |\n",
    "| s.rmul(s2) | s2 * s | Multiplies series |\n",
    "| s.div(s2) s.truediv(s2) | s / s2 | Divides series |\n",
    "|s.rdiv(s2) s.rtruediv(s2)| s2 / s | Divides series|\n",
    "|s.mod(s2)   | s % s2          | Modulo of series division|\n",
    "|s.rmod(s2)  | s2 % s          | Modulo of series division|\n",
    "|s.floordiv(s2) |  s // s2     | Floor divides series|\n",
    "|s.rfloordiv(s2) | s2 // s     | Floor divides series|\n",
    "|s.pow(s2)   | s ** s2         | Exponential power of series|\n",
    "|s.rpow(s2)  | s2 ** s         | Exponential power of series|\n",
    "|s.eq(s2)    | s2 == s         | Elementwise equals of series|\n",
    "|s.ne(s2)    | s2 != s | Elementwise not equals of series|\n",
    "|s.gt(s2) |s > 2| Elementwise greater than of series|\n",
    "|s.ge(s2) |s >= 2| Elementwise greater than or equals of series|\n",
    "|s.lt(s2) |s < 2| Elementwise less than of series|\n",
    "|s.le(s2) |s <= 2 |Elementwise less than or equals of series|\n",
    "|np.invert(s) |~s| Elementwise inversion of boolean series (no pandas method).|\n",
    "|np.logical_and(s, s2) |s & s2 |Elementwise logical and of boolean series (no pandas method).|\n",
    "|np.logical_or(s, s2) |s I s2| Elementwise logical or of boolean series (no pandas method)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal operation::\n",
      "0        22.0\n",
      "1        11.5\n",
      "2        28.0\n",
      "3        11.0\n",
      "4        20.0\n",
      "         ... \n",
      "41139    22.5\n",
      "41140    24.0\n",
      "41141    21.0\n",
      "41142    21.0\n",
      "41143    18.5\n",
      "Length: 41144, dtype: float64\n",
      "chaining::\n",
      "0        22.0\n",
      "1        11.5\n",
      "2        28.0\n",
      "3        11.0\n",
      "4        20.0\n",
      "         ... \n",
      "41139    22.5\n",
      "41140    24.0\n",
      "41141    21.0\n",
      "41142    21.0\n",
      "41143    18.5\n",
      "Length: 41144, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"normal operation::\\n{(city_mpg+highway_mpg)/2}\")\n",
    "print(f\"chaining::\\n{(city_mpg.add(highway_mpg)).div(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Methods\n",
    "\n",
    "Aggregate methods collapse the values of a series down to scaler. It allow you to take detailed data and collapse it to a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of city mpg ::18.369045304297103\n",
      "is_unique ::False\n",
      "is_  monotonic_increase ::False\n"
     ]
    }
   ],
   "source": [
    "# example aggregation method\n",
    "print(f\"mean of city mpg ::{city_mpg.mean()}\")\n",
    "\n",
    "# Few aggregate properties.\n",
    "print(f\"is_unique ::{city_mpg.is_unique}\")\n",
    "print(f\"is_  monotonic_increase ::{city_mpg.is_monotonic_increasing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Series Aggregation](./assets/series%20aggregation.png)\n",
    "- aggregation returns scaler and series as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".8 quantile :: 21.0\n",
      "list of quantile [.1,.5,.8] ::\n",
      "0.1    13.0\n",
      "0.5    17.0\n",
      "0.8    21.0\n",
      "Name: city08, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\".8 quantile :: {city_mpg.quantile(.8)}\")\n",
    "print(f\"list of quantile [.1,.5,.8] ::\\n{city_mpg.quantile(q=[.1,.5,.8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count and Mean of an Attribute\n",
    "trick for calc mean using chaining functions\n",
    "\n",
    "Chaining is also called \"flow\" programming. Rather than making intermediate variables, just leverage the fact that most operations return a new object and work on that.\n",
    "\n",
    "The chain should read like a recipe of ordered steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.965973167412017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    city_mpg\n",
    "    .gt(20)\n",
    "    .multiply(100)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .agg and Aggregation Strings\n",
    "\n",
    "`.agg` methood does aggregation where it shines is in the ability to perform multiple aggregation. We can pass in the names of aggregation methods, Numpy reduction functions, Python aggregation, or define your own aggregation function.\n",
    "\n",
    "\n",
    "\n",
    "| Method |  Description | \n",
    "|--------|--------------|\n",
    "| 'all'  | Returns True if every value is truthy. |\n",
    "| 'any'  | Returns True if any value is truthy. | \n",
    "| 'autocorr' |  Returns Pearson correlation of series with shifted self. Can override lag as keyword argument(default is 1).| \n",
    "| 'corr' | Returns Pearson correlation of series with other series. Need to specify other.  `pearson`,`spearman`, `kendall`, or a callable | \n",
    "| 'count'|  Returns count of non-missing values. | \n",
    "| 'cov' | Return covariance of series with other series. Need to specify other. | \n",
    "| 'dtype'|  Type of the series.| \n",
    "| 'dtypes'|  Type of the series. | \n",
    "| 'empty' | True if no values in series.| \n",
    "| 'hasnans'|  True if missing values in series| \n",
    "| 'idxmax' | Returns index value of maximum value. |\n",
    "| 'idxmin' | Returns index value of minimum value. |\n",
    "| 'is_monotonic' | True if values always increase. |\n",
    "| 'is_monotonic_decreasing'|  True if values always decrease. |\n",
    "| 'is_monotonic_increasing' | True if values always increase. |\n",
    "| 'kurt' | Return ”excess” kurtosis (0 is normal distribution). Values greater than 0 have more outliers than normal. |\n",
    "| 'mad' | Return the mean absolute deviation. |\n",
    "| 'max' | Return the maximum value. |\n",
    "| 'mean'| Return the mean value. |\n",
    "|'median' | Return the median value. |\n",
    "| 'min' | Return the minimum value. |\n",
    "|'nbytes'| Return the number of bytes of the data. |\n",
    "| 'ndim' | Return the number of dimensions (1) of the data. |\n",
    "| 'nunique' | Return the count of unique values.|\n",
    "| 'quantile' | Return the median value. Can override q to specify other quantile.|\n",
    "| 'sem' | Return the unbiased standard error. |\n",
    "| 'size'| Return the size of the data.|\n",
    "|'skew'| Return the unbiased skew of the data. Negative indicates tail is on the left side. |\n",
    "|'std'| Return the standard deviation of the data.|\n",
    "|'sum' |Return the sum of the series.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muthu\\AppData\\Local\\Temp\\ipykernel_8508\\3362801592.py:4: FutureWarning: The provided callable <function min at 0x000001E5DA544700> is currently using Series.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  city_mpg.agg(['mean',np.min,np.var,max,second_to_last])\n",
      "C:\\Users\\muthu\\AppData\\Local\\Temp\\ipykernel_8508\\3362801592.py:4: FutureWarning: The provided callable <function var at 0x000001E5DA545120> is currently using Series.var. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"var\" instead.\n",
      "  city_mpg.agg(['mean',np.min,np.var,max,second_to_last])\n",
      "C:\\Users\\muthu\\AppData\\Local\\Temp\\ipykernel_8508\\3362801592.py:4: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  city_mpg.agg(['mean',np.min,np.var,max,second_to_last])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean               18.369045\n",
       "min                 6.000000\n",
       "var                62.503036\n",
       "max               150.000000\n",
       "second_to_last     18.000000\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def second_to_last(s):\n",
    "    return s.iloc[-2]\n",
    "\n",
    "city_mpg.agg(['mean',np.min,np.var,max,second_to_last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count non-missing value of a series :: 41144\n",
      "number of entries :: 41144\n",
      "number of unique entries:: 105\n",
      "mean :: 18.369045304297103\n",
      "max :: 150\n",
      "using .agg method ::\n",
      "count_notna    41144.000000\n",
      "count          41144.000000\n",
      "nunique          105.000000\n",
      "mean              18.369045\n",
      "max              150.000000\n",
      "Name: city08, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"count non-missing value of a series :: {city_mpg.notna().count()}\")\n",
    "\n",
    "print(f\"number of entries :: {city_mpg.shape[0]}\")\n",
    "\n",
    "print(f\"number of unique entries:: {len(city_mpg.unique())}\")  # .unqiue() returns ndarray\n",
    "\n",
    "print(f\"mean :: {city_mpg.mean()}\")\n",
    "\n",
    "print(f\"max :: {city_mpg.max()}\")\n",
    "\n",
    "\n",
    "def count_notna(s:pd.Series)->int:\n",
    "    return s.dropna().count()\n",
    "print(f\"using .agg method ::\\n{city_mpg.agg([count_notna,'count','nunique','mean','max'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion Methods\n",
    "\n",
    "Sometimes you will need to change the type of the data. This may be due to formats that do not include type information, or it may be that you can have better performance (more manipulation options or use less memory) by changing types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError('cannot safely cast non-equivalent int64 to int8')\n",
      "Explicit type casting\n"
     ]
    }
   ],
   "source": [
    "city_mpg.convert_dtypes('Int8')  # Not recommended. WHY??\n",
    "\n",
    "try:\n",
    "    city_mpg.astype('Int8')\n",
    "except Exception as e:\n",
    "    print(e.__repr__())\n",
    "    print(\"Explicit type casting\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 ::\n",
      "Machine parameters for int64\n",
      "---------------------------------------------------------------\n",
      "min = -9223372036854775808\n",
      "max = 9223372036854775807\n",
      "---------------------------------------------------------------\n",
      "\n",
      "uint8 ::\n",
      "Machine parameters for uint8\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 255\n",
      "---------------------------------------------------------------\n",
      "\n",
      "float16 ::\n",
      "Machine parameters for float16\n",
      "---------------------------------------------------------------\n",
      "precision =   3   resolution = 1.00040e-03\n",
      "machep =    -10   eps =        9.76562e-04\n",
      "negep =     -11   epsneg =     4.88281e-04\n",
      "minexp =    -14   tiny =       6.10352e-05\n",
      "maxexp =     16   max =        6.55040e+04\n",
      "nexp =        5   min =        -max\n",
      "smallest_normal = 6.10352e-05   smallest_subnormal = 5.96046e-08\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"int64 ::\\n{np.iinfo('int64')}\")\n",
    "print(f\"uint8 ::\\n{np.iinfo('uint8')}\")\n",
    "print(f\"float16 ::\\n{np.finfo('float16')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage\n",
    "\n",
    "calc using `.nbytes` and `.memory_usage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :: int64\n",
      "329152\n",
      "329280\n",
      "329280\n"
     ]
    }
   ],
   "source": [
    "print(f\"type :: {city_mpg.dtype}\")\n",
    "\n",
    "print(city_mpg.nbytes)         # only shows how much memory the Pandas object is taking\n",
    "print(city_mpg.memory_usage()) # .memory_usage includes the index memory and can include the contribution from object types\n",
    "\n",
    "print(city_mpg.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String and Category Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str type ::\n",
      "0        19\n",
      "1         9\n",
      "2        23\n",
      "3        10\n",
      "4        17\n",
      "         ..\n",
      "41139    19\n",
      "41140    20\n",
      "41141    18\n",
      "41142    18\n",
      "41143    16\n",
      "Name: city08, Length: 41144, dtype: object\n",
      "category type ::\n",
      "0        19\n",
      "1         9\n",
      "2        23\n",
      "3        10\n",
      "4        17\n",
      "         ..\n",
      "41139    19\n",
      "41140    20\n",
      "41141    18\n",
      "41142    18\n",
      "41143    16\n",
      "Name: city08, Length: 41144, dtype: category\n",
      "Categories (105, int64): [6, 7, 8, 9, ..., 137, 138, 140, 150]\n"
     ]
    }
   ],
   "source": [
    "print(f\"str type ::\\n{city_mpg.astype(str)}\")\n",
    "print(f\"category type ::\\n{city_mpg.astype('category')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered Categories\n",
    "- will define ordered categories.\n",
    "\n",
    "\n",
    "| String or Type |  Description |\n",
    "|----------------|--------------|\n",
    "| str 'str'      | Convert type to Python string |\n",
    "| 'string'       | Convert type to pandas string (supports pd.NA) |\n",
    "| int 'int' 'int64' |  Convert type to NumPy int64 |\n",
    "| 'int32' 'uint32' | Convert type to 32 signed or unsigned NumPy integer (can also use 16 and 8).|\n",
    "| 'Int64' | Convert type to pandas Int64 (supports pd.NA). Might complain when you convert floats or strings.|\n",
    "| float 'float' 'float64' | Convert type to NumPy float64 (can also support 32 or 16). |\n",
    "| 'category' | Convert type to categorical (supports pd.NA). Can also use instance of CategoricalDtype. |\n",
    "| dates | Don’t use this for date conversion, use pd.to_datetime.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in city mpg :: 105\n",
      "type: category\n",
      "ordered city_msg as per values ::\n",
      "0        19\n",
      "1         9\n",
      "2        23\n",
      "3        10\n",
      "4        17\n",
      "         ..\n",
      "41139    19\n",
      "41140    20\n",
      "41141    18\n",
      "41142    18\n",
      "41143    16\n",
      "Name: city08, Length: 41144, dtype: category\n",
      "Categories (105, int64): [6 < 7 < 8 < 9 ... 137 < 138 < 140 < 150]\n"
     ]
    }
   ],
   "source": [
    "values:pd.Series = pd.Series(sorted(set(city_mpg)))\n",
    "\n",
    "print(f\"unique values in city mpg :: {len(values)}\")\n",
    "city_type = pd.CategoricalDtype(categories=values,ordered=True)\n",
    "print(f\"type: {city_type}\")\n",
    "\n",
    "print(f\"ordered city_msg as per values ::\\n{city_mpg.astype(city_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Other Types\n",
    "\n",
    "- to_sql\n",
    "- to_dict\n",
    "- to_excel\n",
    "- to_parquet\n",
    "- to_json...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       city08\n",
      "0          19\n",
      "1           9\n",
      "2          23\n",
      "3          10\n",
      "4          17\n",
      "...       ...\n",
      "41139      19\n",
      "41140      20\n",
      "41141      18\n",
      "41142      18\n",
      "41143      16\n",
      "\n",
      "[41144 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(city_mpg.to_frame())  # move to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Manipulation Methods\n",
    "workhorses of pandas\n",
    "- understand\n",
    "- clean up\n",
    "- model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .apply and .where\n",
    "\n",
    ".apply method allows you to apply a function element-wise to every value/\n",
    "Setback : If you million reocrds, it will be called million times. It breaks out the fast vectorized code paths we can leverage in pandas and puts back to string slow python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt20(val):\n",
    "    return val>20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.54 ms ± 259 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "city_mpg.apply(gt20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.4 µs ± 1 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "city_mpg.gt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Alfa Romeo\n",
      "1           Ferrari\n",
      "2             Dodge\n",
      "3             Dodge\n",
      "4            Subaru\n",
      "            ...    \n",
      "41139        Subaru\n",
      "41140        Subaru\n",
      "41141        Subaru\n",
      "41142        Subaru\n",
      "41143        Subaru\n",
      "Name: make, Length: 41144, dtype: object\n"
     ]
    }
   ],
   "source": [
    "make = df['make']\n",
    "print(make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = make.value_counts().index[:5]\n",
    "def generalize_top5(val):\n",
    "    if val in top5: return val\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.7 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "make.apply(generalize_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71 ms ± 36.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "make.where(make.isin(top5),other=\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![leverage .where method](./assets/where%20method.png)\n",
    "\n",
    "By Seeing above example, we can verify signifiant change in time\n",
    "\n",
    "`.mask` will do opposite way.\n",
    "- if condition is False it'll keep original value\n",
    "- if condition is True  it'll assign new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying mask method ::\n",
      "0        Other\n",
      "1        Other\n",
      "2        Dodge\n",
      "3        Dodge\n",
      "4        Other\n",
      "         ...  \n",
      "41139    Other\n",
      "41140    Other\n",
      "41141    Other\n",
      "41142    Other\n",
      "41143    Other\n",
      "Name: make, Length: 41144, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# make.where(make.isin(top5),other=\"Other\") Equivalent\n",
    "print(f\"applying mask method ::\\n{make.mask(~make.isin(top5),other='Other')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Else\n",
    "- by applying `.mask`, `.where` in chaining fashion\n",
    "- `np.select` longer if else statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = make.value_counts()\n",
    "top5 = vc.index[:5]\n",
    "top10= vc.index[:10]\n",
    "\n",
    "def generalize(val):\n",
    "    if val in top5: return 'top5'\n",
    "    if val in top10: return 'top10'\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.3 ms ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "make.apply(generalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.89 ms ± 287 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.Series(\n",
    "    data= np.select(\n",
    "        condlist  = [make.isin(top5),make.isin(top10)],\n",
    "        choicelist= ['top5','top10'],\n",
    "        default  =\"Other\"\n",
    "        ),\n",
    "    index=make.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "many ML algorithms do not work if there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of na :: 206\n",
      "missing ::\n",
      "7138     Nissan\n",
      "7139     Toyota\n",
      "8143     Toyota\n",
      "8144       Ford\n",
      "8146       Ford\n",
      "          ...  \n",
      "34563     Tesla\n",
      "34564     Tesla\n",
      "34565     Tesla\n",
      "34566     Tesla\n",
      "34567     Tesla\n",
      "Name: make, Length: 206, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cyl = df['cylinders']\n",
    "print(f\"number of na :: {cyl.isna().sum()}\")\n",
    "\n",
    "print(f\"missing ::\\n{make.loc[cyl.isna()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Telsa car because it has electric engine, not combustion engine - has ZERO cylinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Data\n",
    "\n",
    "![ways of filling missing data](./assets/missing%20data%20for%20series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating Data\n",
    "\n",
    "Other operation for replacing missing data is `.interpolate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp::\n",
      "0    32.0\n",
      "1    40.0\n",
      "2     NaN\n",
      "3    42.0\n",
      "4    39.0\n",
      "5    32.0\n",
      "dtype: float64\n",
      "interpolate temp ::\n",
      "0    32.0\n",
      "1    40.0\n",
      "2    41.0\n",
      "3    42.0\n",
      "4    39.0\n",
      "5    32.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "temp = pd.Series([32,40,None,42,39,32])\n",
    "print(f\"temp::\\n{temp}\")\n",
    "\n",
    "print(f\"interpolate temp ::\\n{temp.interpolate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping \n",
    "\n",
    "In fact, if you dig into the implementation of .clip, you will see a call to .where. Below is a\n",
    "portion of the ._clip_with_scalar method that .clip calls:\n",
    "\n",
    "```python\n",
    "if upper is not None :\n",
    "    subset = self . to_numpy () <= upper\n",
    "    result = result . where ( subset , upper )\n",
    "if lower is not None :\n",
    "    subset = self . to_numpy () >= lower\n",
    "    result = result . where ( subset , lower )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      19\n",
       "1       9\n",
       "2      23\n",
       "3      10\n",
       "4      17\n",
       "       ..\n",
       "442    15\n",
       "443    15\n",
       "444    15\n",
       "445    15\n",
       "446    31\n",
       "Name: city08, Length: 447, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.loc[:446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile:.05 :: 11.0\n",
      "quantile:.95 :: 27.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      19\n",
       "1      11\n",
       "2      23\n",
       "3      11\n",
       "4      17\n",
       "       ..\n",
       "442    15\n",
       "443    15\n",
       "444    15\n",
       "445    15\n",
       "446    27\n",
       "Name: city08, Length: 447, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"quantile:.05 :: {city_mpg.quantile(.05)}\")\n",
    "print(f\"quantile:.95 :: {city_mpg.quantile(.95)}\")\n",
    "(\n",
    "    city_mpg\n",
    "        .loc[:446]\n",
    "        .clip(lower=city_mpg.quantile(.05), upper=city_mpg.quantile(0.95))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7901       6\n",
       "34557      6\n",
       "37161      6\n",
       "21060      6\n",
       "35887      6\n",
       "        ... \n",
       "34563    138\n",
       "34564    140\n",
       "32599    150\n",
       "31256    150\n",
       "33423    150\n",
       "Name: city08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Duplicates\n",
    "\n",
    "Many datasets have duplicate entries. whether to keep the first or last duplicate value found using\n",
    "the keep parameter.\n",
    "```py\n",
    ".drop_duplicates(keep=\"first\")   # default\n",
    ".drop_duplicates(keep=\"last\") \n",
    ".drop_duplicates(keep=False)\n",
    "```\n",
    "\n",
    "![Drop Duplicates](./assets/drop%20duplicates.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8147      84\n",
       "23028     59\n",
       "23029     79\n",
       "24471    107\n",
       "25699     60\n",
       "25953     93\n",
       "32740    131\n",
       "32842    125\n",
       "34173    123\n",
       "34364    127\n",
       "34409    114\n",
       "34564    140\n",
       "34565    115\n",
       "34566    104\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Data\n",
    "\n",
    "`.rank` method will return a series that keeps the original index but uses the ranks of values from\n",
    "the original series\n",
    "\n",
    "- average: average rank of the group\n",
    "- min: lowest rank in the group\n",
    "- max: highest rank in the group\n",
    "- first: ranks assigned in order they appear in the array\n",
    "- dense: like 'min', but rank always increases by 1 between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        27060.5\n",
       "1          235.5\n",
       "2        35830.0\n",
       "3          607.5\n",
       "4        19484.0\n",
       "          ...   \n",
       "41139    27060.5\n",
       "41140    29719.5\n",
       "41141    23528.0\n",
       "41142    23528.0\n",
       "41143    15479.0\n",
       "Name: city08, Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.rank(method='average') #method = ['average', 'min', 'max', 'first', 'dense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25555.0\n",
       "1          136.0\n",
       "2        35119.0\n",
       "3          336.0\n",
       "4        17467.0\n",
       "          ...   \n",
       "41139    25555.0\n",
       "41140    28567.0\n",
       "41141    21502.0\n",
       "41142    21502.0\n",
       "41143    13492.0\n",
       "Name: city08, Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.rank(method='min') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14.0\n",
       "1         4.0\n",
       "2        18.0\n",
       "3         5.0\n",
       "4        12.0\n",
       "         ... \n",
       "41139    14.0\n",
       "41140    15.0\n",
       "41141    13.0\n",
       "41142    13.0\n",
       "41143    11.0\n",
       "Name: city08, Length: 41144, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.rank(method='dense') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Data\n",
    "\n",
    "`.replace` method allows you to map values to new values. \n",
    "we can add regex by rege=True parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Alfa Romeo\n",
       "1           Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4             スバル ⚡\n",
       "            ...    \n",
       "41139         スバル ⚡\n",
       "41140         スバル ⚡\n",
       "41141         スバル ⚡\n",
       "41142         スバル ⚡\n",
       "41143         スバル ⚡\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.replace('Subaru','スバル ⚡')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Alfa Romeo\n",
       "1        ri-muthu-Fer\n",
       "2               Dodge\n",
       "3               Dodge\n",
       "4              Subaru\n",
       "             ...     \n",
       "41139          Subaru\n",
       "41140          Subaru\n",
       "41141          Subaru\n",
       "41142          Subaru\n",
       "41143          Subaru\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.replace(to_replace=r'(Fer)ra(r.*)',value=r'\\2-muthu-\\1',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning\n",
    "bin data. by using `.cut` or `qcut` options\n",
    "\n",
    "- `.cut` splits data into equal parts and returns dtype as category if you specifc size of bins edges we can specify those\n",
    "\n",
    "- `qcut`can bin data with quantiles instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (5.856, 20.4]\n",
       "1        (5.856, 20.4]\n",
       "2         (20.4, 34.8]\n",
       "3        (5.856, 20.4]\n",
       "4        (5.856, 20.4]\n",
       "             ...      \n",
       "41139    (5.856, 20.4]\n",
       "41140    (5.856, 20.4]\n",
       "41141    (5.856, 20.4]\n",
       "41142    (5.856, 20.4]\n",
       "41143    (5.856, 20.4]\n",
       "Name: city08, Length: 41144, dtype: category\n",
       "Categories (10, interval[float64, right]): [(5.856, 20.4] < (20.4, 34.8] < (34.8, 49.2] < (49.2, 63.6] ... (92.4, 106.8] < (106.8, 121.2] < (121.2, 135.6] < (135.6, 150.0]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(city_mpg,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (10, 20]\n",
       "1         (0, 10]\n",
       "2        (20, 40]\n",
       "3         (0, 10]\n",
       "4        (10, 20]\n",
       "           ...   \n",
       "41139    (10, 20]\n",
       "41140    (10, 20]\n",
       "41141    (10, 20]\n",
       "41142    (10, 20]\n",
       "41143    (10, 20]\n",
       "Name: city08, Length: 41144, dtype: category\n",
       "Categories (5, interval[int64, right]): [(0, 10] < (10, 20] < (20, 40] < (40, 70] < (70, 150]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(city_mpg,[0,10,20,40,70,150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (18.0, 20.0]\n",
       "1        (5.999, 13.0]\n",
       "2         (21.0, 24.0]\n",
       "3        (5.999, 13.0]\n",
       "4         (16.0, 17.0]\n",
       "             ...      \n",
       "41139     (18.0, 20.0]\n",
       "41140     (18.0, 20.0]\n",
       "41141     (17.0, 18.0]\n",
       "41142     (17.0, 18.0]\n",
       "41143     (15.0, 16.0]\n",
       "Name: city08, Length: 41144, dtype: category\n",
       "Categories (10, interval[float64, right]): [(5.999, 13.0] < (13.0, 14.0] < (14.0, 15.0] < (15.0, 16.0] ... (18.0, 20.0] < (20.0, 21.0] < (21.0, 24.0] < (24.0, 150.0]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(city_mpg,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1     13.0\n",
       "0.2     14.0\n",
       "0.3     15.0\n",
       "0.4     16.0\n",
       "0.5     17.0\n",
       "0.6     18.0\n",
       "0.7     20.0\n",
       "0.8     21.0\n",
       "0.9     24.0\n",
       "1.0    150.0\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.quantile([.1,.2,.3,.4,.5,.6,.7,.8,.9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7\n",
       "1        1\n",
       "2        9\n",
       "3        1\n",
       "4        5\n",
       "        ..\n",
       "41139    7\n",
       "41140    7\n",
       "41141    6\n",
       "41142    6\n",
       "41143    4\n",
       "Name: city08, Length: 41144, dtype: category\n",
       "Categories (10, int64): [1 < 2 < 3 < 4 ... 7 < 8 < 9 < 10]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(city_mpg,10,labels=list(range(1,11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing Operation\n",
    "\n",
    "Indexing is an overloaded term in the pandas world. Both a series and a dataframe have an index.\n",
    "\n",
    "- `.iloc` and `loc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=41144, step=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Alfa Romeo\n",
       "first       Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4            Subaru\n",
       "            ...    \n",
       "41139        Subaru\n",
       "41140        Subaru\n",
       "41141        Subaru\n",
       "41142        Subaru\n",
       "41143        Subaru\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.rename(index={1:'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id-0        Alfa Romeo\n",
       "id-1           Ferrari\n",
       "id-2             Dodge\n",
       "id-3             Dodge\n",
       "id-4            Subaru\n",
       "               ...    \n",
       "id-41139        Subaru\n",
       "id-41140        Subaru\n",
       "id-41141        Subaru\n",
       "id-41142        Subaru\n",
       "id-41143        Subaru\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_str(val):\n",
    "    return f\"id-{val}\"\n",
    "\n",
    "make.rename(to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Alfa Romeo\n",
       "1           Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4            Subaru\n",
       "            ...    \n",
       "41139        Subaru\n",
       "41140        Subaru\n",
       "41141        Subaru\n",
       "41142        Subaru\n",
       "41143        Subaru\n",
       "Name: first, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.rename(index=\"first\")  # Change name of Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>city08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>41139</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>41140</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>41141</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>41142</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>41143</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  city08\n",
       "0          0      19\n",
       "1          1       9\n",
       "2          2      23\n",
       "3          3      10\n",
       "4          4      17\n",
       "...      ...     ...\n",
       "41139  41139      19\n",
       "41140  41140      20\n",
       "41141  41141      18\n",
       "41142  41142      18\n",
       "41143  41143      16\n",
       "\n",
       "[41144 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "2        23\n",
       "3        10\n",
       "4        17\n",
       "         ..\n",
       "41139    19\n",
       "41140    20\n",
       "41141    18\n",
       "41142    18\n",
       "41143    16\n",
       "Name: city08, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_mpgs</th>\n",
       "      <th>city08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>41139</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>41140</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>41141</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>41142</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>41143</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_mpgs  city08\n",
       "0              0      19\n",
       "1              1       9\n",
       "2              2      23\n",
       "3              3      10\n",
       "4              4      17\n",
       "...          ...     ...\n",
       "41139      41139      19\n",
       "41140      41140      20\n",
       "41141      41141      18\n",
       "41142      41142      18\n",
       "41143      41143      16\n",
       "\n",
       "[41144 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.rename_axis('city_mpgs').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .loc Attributes\n",
    "\n",
    "`.loc` attribute deals with index labels.\n",
    " \n",
    "- A scalar value of one of the index labels\n",
    "- A list of index labels.\n",
    "- A slice of labels (closed interval so it includes the stop value).\n",
    "- An index.\n",
    "- A boolean array (same index labels as the series, but with True or False values.\n",
    "- A function that accepts a series and returns one of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge120</th>\n",
       "      <th>city08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31522</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33087</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33088</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       charge120  city08\n",
       "28144        0.0      16\n",
       "28145        0.0      16\n",
       "29612        0.0      16\n",
       "29613        0.0      16\n",
       "29751        0.0      16\n",
       "30450        0.0      16\n",
       "30561        0.0      16\n",
       "30562        0.0      16\n",
       "30728        0.0      16\n",
       "30783        0.0      16\n",
       "31519        0.0      16\n",
       "31522        0.0      16\n",
       "31526        0.0      16\n",
       "31527        0.0      16\n",
       "33077        0.0      16\n",
       "33087        0.0      16\n",
       "33088        0.0      16"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(city_mpg>15) & (make=='Ferrari'),['charge120','city08']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33077    16\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.loc[pd.Index([33077])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melon      4.389\n",
       "Carrots    3.069\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = pd.Series([1.,2.25,3.99,.99,2.79],index=['Gum','Cookie','Melon','Roll','Carrots'])\n",
    "\n",
    "inflation = 1.10\n",
    "\n",
    "def gt3(s):\n",
    "    return s>3\n",
    "gt3 = lambda s:s>3\n",
    "\n",
    "cost.multiply(inflation).loc[lambda s_:s_>3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .iloc\n",
    "\n",
    "The series also supports indexing off of the .iloc attribute, we pull out items by index position.\n",
    "\n",
    "- A scalar index position (an integer)\n",
    "- A list of index positions\n",
    "- A slice of positions (half-open interval so it does not include stop value).\n",
    "- A NumPy array (or Python list) of boolean values.\n",
    "- A function that accepts a series and returns one of the above.\n",
    "\n",
    "\n",
    "However, I have not found a real-life use case for passing in a function. Because I would use such functionality to pull out values on the result of a chained method call, using .loc is preferred as it accepts a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         9\n",
       "41143    16\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.iloc[[0,1,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1     9\n",
       "2    23\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heads and tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_mpg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_mpg.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11439    12\n",
       "22260    16\n",
       "32152    18\n",
       "31045    24\n",
       "23322    14\n",
       "4339     16\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.sample(6,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Index Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ford      3371\n",
       "Subaru     885\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.value_counts().filter(items=['Ford','Subaru'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make\n",
       "Ford    3371\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.value_counts().filter(like='ord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make\n",
       "Ford      3371\n",
       "Subaru     885\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.value_counts().filter(regex='(Ford)|(Subaru)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing\n",
    "\n",
    "The .reindex method allows you to pull out values by index label. It will conform the series or\n",
    "return a series with the order of the index labels provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  String Manipulation\n",
    "\n",
    "String data is commonly used to hold free-form text, semi-structured text, categorical data and data shold have another type (numbers and datetime.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of make:: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"dtype of make:: {make.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Alfa Romeo\n",
       "1           Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4            Subaru\n",
       "            ...    \n",
       "41139        Subaru\n",
       "41140        Subaru\n",
       "41141        Subaru\n",
       "41142        Subaru\n",
       "41143        Subaru\n",
       "Name: make, Length: 41144, dtype: string"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.astype('string') ## Supports NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Strings\n",
    "\n",
    "if we've low cardinality string columns, consider using a categorical type for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Alfa Romeo\n",
       "1           Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4            Subaru\n",
       "            ...    \n",
       "41139        Subaru\n",
       "41140        Subaru\n",
       "41141        Subaru\n",
       "41142        Subaru\n",
       "41143        Subaru\n",
       "Name: make, Length: 41144, dtype: category\n",
       "Categories (136, object): ['AM General', 'ASC Incorporated', 'Acura', 'Alfa Romeo', ..., 'Volvo', 'Wallace Environmental', 'Yugo', 'smart']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The .str Accessor\n",
    "\n",
    "'Object' , 'string' and 'category' type have a .str accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        alfa romeo\n",
       "1           ferrari\n",
       "2             dodge\n",
       "3             dodge\n",
       "4            subaru\n",
       "            ...    \n",
       "41139        subaru\n",
       "41140        subaru\n",
       "41141        subaru\n",
       "41142        subaru\n",
       "41143        subaru\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1       -1\n",
       "2       -1\n",
       "3       -1\n",
       "4       -1\n",
       "        ..\n",
       "41139   -1\n",
       "41140   -1\n",
       "41141   -1\n",
       "41142   -1\n",
       "41143   -1\n",
       "Name: make, Length: 41144, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.str.find('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41144 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "...    ...\n",
       "41139  NaN\n",
       "41140  NaN\n",
       "41141  NaN\n",
       "41142  NaN\n",
       "41143  NaN\n",
       "\n",
       "[41144 rows x 1 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.str.extract(f'([^a-z A-Z])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age bins ::\n",
      "0     0 -10 \n",
      "1    11 -15 \n",
      "2    11 -15 \n",
      "3    61 -65 \n",
      "4    46 -50 \n",
      "dtype: object\n",
      "split age::\n",
      "  lower bound upper bound\n",
      "0          0          10 \n",
      "1         11          15 \n",
      "2         11          15 \n",
      "3         61          65 \n",
      "4         46          50 \n"
     ]
    }
   ],
   "source": [
    "age = pd . Series ([ '0 -10 ' , '11 -15 ' , '11 -15 ' , '61 -65 ' , '46 -50 '])\n",
    "\n",
    "print(f\"age bins ::\\n{age}\")\n",
    "\n",
    "print(f\"split age::\\n{age.str.split('-',expand=True).rename(columns={0:'lower bound',1:'upper bound'})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    15\n",
       "2    15\n",
       "3    65\n",
       "4    50\n",
       "dtype: Int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.str.slice(-3).str.strip().astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Optimizing .apply with Cython\n",
    "\n",
    "Cython is a superset of Python that can compile to native code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "%load_ext Cython\n",
    "\n",
    "%%cython\n",
    "import random \n",
    "def between_cy(row):\n",
    "    return random.randint(*row.values)\n",
    "\n",
    "%%cython\n",
    "import random\n",
    "cpdef int between_cy3(int x,int y):\n",
    "    return random.randint(x,y)\n",
    "\n",
    "\n",
    "age.str.split('-',expand=True)\n",
    "    .astype(int)\n",
    "    .apply(lambda row:between_cy3 (row [0],row [1]),axis =1)\n",
    "\n",
    "\n",
    "%prun -l 10 age.str.split('-',expand=True).astype(int).apply(lambda row:between_cy3 (row [0],row [1]),axis =1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%% cython\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import random\n",
    "    cpdef np.ndarray[int] apply_between_cy4(np.ndarray[int] x , np.ndarray[int] y ):\n",
    "        cdef np.ndarray[int] res = np.empty (len(x), dtype='int32')\n",
    "            for i in range ( len ( x )):\n",
    "                res [ i ] = random . randint ( x [ i ] , y [ i ])\n",
    "            return res\n",
    "\n",
    "age.str.split('-',expand=True).astype(int)\n",
    "    .pipe(lambda df_ : apply_between_cy4 ( \n",
    "            df_ . iloc [: , 0]. to_numpy ( dtype = ' int32 ') ,\n",
    "            df_ . iloc [: , 1]. to_numpy ( dtype = ' int32 ')\n",
    "        ))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        🍎lfa Romeo\n",
       "1           Ferrari\n",
       "2             Dodge\n",
       "3             Dodge\n",
       "4            Subaru\n",
       "            ...    \n",
       "41139        Subaru\n",
       "41140        Subaru\n",
       "41141        Subaru\n",
       "41142        Subaru\n",
       "41143        Subaru\n",
       "Name: make, Length: 41144, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make.str.replace('A','🍎')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Date and Time Manipulation\n",
    "Pandas allows you to create series with date and time information in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading UTC Time Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Local Time Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Time to UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Converting to Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Manipulating Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dates in the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filling in missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intepolation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropping missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shifting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rolling average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gathering aggregate values(but keeping index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## groupby operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cumulative operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plotting with a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting in jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line plot with multiple aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## pie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## styling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Categorical Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benefits of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversion to Ordinal categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .cat accessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## category gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## database and spreedsheet analogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple python version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Similarities with Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Math Methods in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicate index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Looping and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregaions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .apply method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Columns Types, .assign an Memory Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Creating and Updating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more column cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dealing with Missing and Duplicated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sorting Columns and Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soring columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sorting columns Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting and Sorting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Filtering and Indexing Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetting the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Indexing, Filtering & Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing by Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plotting with DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## area and stacked bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## column distributions with KDEs,Histograms and Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reshaping Dataframes with Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## undoing dummy columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reshaping By Pivoting and Grouping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a custom Aggregation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## per column aggregations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grouping by hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grouping with functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  More Aggregations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation while keeping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering parts of groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cross-tabulation Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding margins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalizing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hierarchical columns with cross tabulations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Melting, Transpose and Stacking Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Un-melting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transposing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## stacking and Unstacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Flattening hierarchical index and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Working with TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## adding timezone info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## slicing ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## missing ts data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## exploring seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## resampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## rules with offset aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## combining offset aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## anchored offset aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## resampling to finger-grain frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## grouping a date column with pd.Grouper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Joining Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rows to Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding cols to Dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joins indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge validations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining data example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dirty devil flow and weather data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validating joined data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of merged data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exporting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty devil data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Styling Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparklines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## .style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Embedding Bar plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Heatmap and gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## css properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## stickiness and hidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hiding the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Debugging pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if Dataframe are Equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Chains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
